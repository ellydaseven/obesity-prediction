{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6d1ae2",
   "metadata": {},
   "source": [
    "# MODEL CREATION AND TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b6cfb3",
   "metadata": {},
   "source": [
    "In this notebook, we will now create our model to be used by the system. We will explore different ML algorithms, and build models, examine their performances, and via the performance metrics, we will choose the best model, and employ it in our system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd33c5e5",
   "metadata": {},
   "source": [
    "The algorithms to be used are classification algorithms, since our problem is a classification one. The algorithms to be used are:\n",
    "Logistic Regression,\n",
    "Random Forest,\n",
    "K- nearest neighbor,\n",
    "Naive Bayes Classifier,\n",
    "Voting Classifier (ensemble algorithm), and\n",
    "Stacking Classifier (ensemble algorithm)\n",
    "\n",
    "We will use k-fold cross validation, to examine the performances of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b323b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db4b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "data = pd.read_csv(\"obesity_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e826b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the features, and the target variable\n",
    "\n",
    "x = data.drop('Obesity Status', axis=1)\n",
    "y = data['Obesity Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdffb8ab",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01c23ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating the model and splitting the dataset\n",
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.75,test_size=0.25)\n",
    "\n",
    "log_reg = model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6feaaa9",
   "metadata": {},
   "source": [
    "### Using k-fold cross validation to assess the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66e863f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8754716981132076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(log_reg, x_train, y_train, scoring = 'accuracy', cv = 5)\n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1d9363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8733333333333334\n"
     ]
    }
   ],
   "source": [
    "# Scores on test data\n",
    "\n",
    "test_score  = cross_val_score(log_reg, x_test, y_test, scoring = 'accuracy', cv = 5)\n",
    "print(np.mean(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b747cea",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef14cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating the model and splitting the dataset\n",
    "\n",
    "nb = GaussianNB()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "nb_model = nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a70fb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7137218045112783\n"
     ]
    }
   ],
   "source": [
    "# Assessment via k-fold cross validation\n",
    "# On training set\n",
    "from sklearn.model_selection import cross_val_score\n",
    "score2 = cross_val_score(nb_model, x_train, y_train, scoring = 'accuracy', cv = 5)\n",
    "print(np.mean(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "776a8773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5361904761904762\n"
     ]
    }
   ],
   "source": [
    "# On test set\n",
    "test_score2  = cross_val_score(nb_model, x_test, y_test, scoring = 'accuracy', cv = 5)\n",
    "print(np.mean(test_score2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f08afb",
   "metadata": {},
   "source": [
    "## 3. K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10badb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating the model and splitting the dataset\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)\n",
    "\n",
    "knn_model = knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad68184c",
   "metadata": {},
   "source": [
    "### Using k-fold cross validation to assess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "822ab786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8796992481203008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score3 = cross_val_score(knn_model, x_train, y_train, scoring = 'accuracy', cv = 5)\n",
    "print(np.mean(score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b37158ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8295238095238094\n"
     ]
    }
   ],
   "source": [
    "# Scores on test set\n",
    "\n",
    "test_score3  = cross_val_score(knn_model, x_test, y_test, scoring = 'accuracy', cv = 5)\n",
    "print(np.mean(test_score3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8efa44",
   "metadata": {},
   "source": [
    "## 4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b62c575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating the model and splitting the dataset\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=4)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.80, test_size=0.20, stratify=y)\n",
    "\n",
    "rfc_model = rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c501a436",
   "metadata": {},
   "source": [
    "### Using k-fold cross validation to assess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c46d76a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7843984962406014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score4 = cross_val_score(rfc_model, x_train, y_train, scoring = 'accuracy', cv = 5)\n",
    "print(np.mean(score4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32c69cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6752380952380952\n"
     ]
    }
   ],
   "source": [
    "# On test data \n",
    "\n",
    "test_score4  = cross_val_score(rfc_model, x_test, y_test, scoring = 'accuracy', cv = 5)\n",
    "print(np.mean(test_score4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af61a70",
   "metadata": {},
   "source": [
    "It was observed that, in Random Forest, as the value of 'n_estimators' increased, the computational time of the cross validation increased, while its accuracy scores decreased. Thus, 'n_estimators' is directly proportional to computational time, and inversely proportional to accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab133fb",
   "metadata": {},
   "source": [
    "## Onto the ensemble classifiers..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65687c9c",
   "metadata": {},
   "source": [
    "## 5. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7c9ab70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.55%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Splitting the data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, stratify=y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Creating the submodels\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('Logistic',model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart',model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm',model3))\n",
    "\n",
    "\n",
    "# Define the model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "\n",
    "# Fit the model\n",
    "ensemble.fit(x_train,y_train)\n",
    "\n",
    "# Predictions \n",
    "y_predict = ensemble.predict(x_test)\n",
    "\n",
    "# Accuracy computation\n",
    "from sklearn.metrics import accuracy_score\n",
    "model_score = accuracy_score(y_test,y_predict)\n",
    "print(\"{:.2f}%\".format(model_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c47ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.92      1.00      0.96        12\n",
      "           2       0.80      1.00      0.89        12\n",
      "           3       1.00      0.75      0.86        12\n",
      "           4       0.91      0.83      0.87        12\n",
      "           5       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.92        71\n",
      "   macro avg       0.92      0.92      0.91        71\n",
      "weighted avg       0.92      0.92      0.91        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "report = classification_report(y_test, y_predict)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9be350",
   "metadata": {},
   "source": [
    "## 6. Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87a9ff8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;dt&#x27;, DecisionTreeClassifier()),\n",
       "                               (&#x27;nb&#x27;, GaussianNB()),\n",
       "                               (&#x27;rf&#x27;, RandomForestClassifier()),\n",
       "                               (&#x27;knn&#x27;, KNeighborsClassifier())],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;dt&#x27;, DecisionTreeClassifier()),\n",
       "                               (&#x27;nb&#x27;, GaussianNB()),\n",
       "                               (&#x27;rf&#x27;, RandomForestClassifier()),\n",
       "                               (&#x27;knn&#x27;, KNeighborsClassifier())],\n",
       "                   final_estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>nb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('dt', DecisionTreeClassifier()),\n",
       "                               ('nb', GaussianNB()),\n",
       "                               ('rf', RandomForestClassifier()),\n",
       "                               ('knn', KNeighborsClassifier())],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#The weak learner models in the stacking method \n",
    "\n",
    "estimators = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('nb', GaussianNB()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "# Building the stack model\n",
    "\n",
    "stack_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# Splitting the dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Training the dataset\n",
    "\n",
    "stack_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efb5ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.88      0.93      0.90        15\n",
      "           2       0.91      1.00      0.95        10\n",
      "           3       1.00      1.00      1.00        10\n",
      "           4       1.00      0.83      0.91        12\n",
      "           5       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.96        71\n",
      "   macro avg       0.96      0.96      0.96        71\n",
      "weighted avg       0.96      0.96      0.96        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = stack_model.predict(x_test)\n",
    "\n",
    "# Performance evaluation\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abf9132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.77%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "from sklearn.metrics import accuracy_score\n",
    "model_score = accuracy_score(y_test,y_pred)\n",
    "print(\"{:.2f}%\".format(model_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2c693",
   "metadata": {},
   "source": [
    "The ensemble algorithms have recorded very high values of accuracy, with the Voting Classifier having a 91.55% accuracy, and the Stacking Classifier having a 96% accuracy. This may be due to the fact that, these algorithms employ multiple individual algorithms like logistic regression, SVM, KNN, etc., and they use them to improve on the general accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68c0ec",
   "metadata": {},
   "source": [
    "Let's create a dummy input, to try and see the prediction. This will mirror the actual system, as the system will take input, process them in a numpy array, send it to the model, and retrieving prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68127fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "# Dummy input\n",
    "\n",
    "\n",
    "test_case = [23, 167, 120, 0, 0, 1, 1, 1]\n",
    "test = np.array([test_case])\n",
    "\n",
    "df = pd.DataFrame(test)\n",
    "test_pred = stack_model.predict(df)\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ae9c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Stacking Classifier model\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = 'obesitymodel.sav'\n",
    "pickle.dump(stack_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4b9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
